{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0015a646",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Author: Young Beum Cho\n",
    "# Kroll Lab, Department of Developmental Biology\n",
    "# Program for gene list + keyword searching on ncbi/gds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae9391ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2258e",
   "metadata": {},
   "source": [
    "# Execute above and below cells first\n",
    "* To change the keyword search targets, modify search_element function\n",
    "# First-level functions\n",
    "\n",
    "The code below contains several first-level functions that serve different purposes in the web scraping process. These functions include:\n",
    "\n",
    "- `search_element(element)`: This function constructs the search query to be used in the search box.\n",
    "- `open_geo()`: This function opens the Geo website using a Chrome driver.\n",
    "- `set_box(dr)`: This function finds and sets the search box element.\n",
    "- `set_btn(dr)`: This function finds and sets the search button element.\n",
    "- `set_next1(dr)`: This function finds and sets the next button element (if it exists).\n",
    "- `set_next2(dr)`: This function finds and sets the next button element (if it exists).\n",
    "- `check_exists_by_xpath(xpath, dr)`: This function checks if an element exists based on the given XPath.\n",
    "- `type_click(str, box, btn)`: This function types the search query and clicks the search button.\n",
    "- `click_next(next_btn)`: This function clicks the next button.\n",
    "- `clearBox(box)`: This function clears the search box.\n",
    "- `one_page_all_title(page)`: This function retrieves all titles appearing on the searched page.\n",
    "- `one_page_all_url(page)`: This function retrieves all URLs linked to each individual search result.\n",
    "- `page_num(page)`: This function retrieves the current page number and the last page number.\n",
    "- `get_response(url)`: This function retrieves the response from a given URL.\n",
    "\n",
    "Please note that this Markdown cell provides a brief overview of the functions included in the code. For more details on each function's implementation and usage, please refer to the code itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a664a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first-level functions\n",
    "\n",
    "#what will go into the search box with elements as every genes\n",
    "def search_element(element):\n",
    "    return r'\"' + element + r'\" & ' + r'\"' + \"homo sapiens\" + r'\" & \"' + \"Genome binding/occupancy profiling by high throughput sequencing\" + r'\"'\n",
    "\n",
    "#open url\n",
    "def open_geo():\n",
    "    #open geo website\n",
    "    driver = Chrome(\"chromedriver.exe\")\n",
    "    time.sleep(1)\n",
    "    url = 'https://www.ncbi.nlm.nih.gov/gds/'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    return driver\n",
    "\n",
    "#find and set search box   \n",
    "def set_box(dr):\n",
    "    driver = dr\n",
    "    search_box_path = '//*[@id=\"term\"]'\n",
    "    #set search box as variable\n",
    "    search_box = driver.find_element(\"xpath\", search_box_path)\n",
    "    return search_box\n",
    "\n",
    "#find and set search button\n",
    "def set_btn(dr):\n",
    "    driver = dr\n",
    "    search_btn_path = '//*[@id=\"search\"]'\n",
    "    #set search box as variable\n",
    "    search_btn = driver.find_element(\"xpath\",search_btn_path)\n",
    "    return search_btn\n",
    "\n",
    "#find and set next button\n",
    "def set_next1(dr):\n",
    "    next_btn_path = '//*[@id=\"EntrezSystem2.PEntrez.Gds.Gds_ResultsPanel.Entrez_Pager.Page\"]'\n",
    "    #check if next button exists\n",
    "    status = check_exists_by_xpath(next_btn_path, dr)\n",
    "    if(status==1):\n",
    "        next_btn = driver.find_element(\"xpath\",next_btn_path)\n",
    "        return next_btn\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#find and set next button\n",
    "def set_next2(dr):\n",
    "    next_btn_path = '/html/body/div[1]/div[1]/form/div[1]/div[4]/div/div[3]/div[2]/a[3]'\n",
    "    #check if next button exists\n",
    "    status = check_exists_by_xpath(next_btn_path, dr)\n",
    "    if(status==1):\n",
    "        next_btn = driver.find_element(\"xpath\",next_btn_path)\n",
    "        return next_btn\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def check_exists_by_xpath(xpath, dr):\n",
    "    driver = dr\n",
    "    try:\n",
    "        driver.find_element(\"xpath\",xpath)\n",
    "    except NoSuchElementException:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "#type and click\n",
    "def type_click(str, box, btn):\n",
    "    search_box = box\n",
    "    search_btn = btn\n",
    "    search_box.send_keys(search_element(str))\n",
    "    search_btn.click()\n",
    "    \n",
    "def click_next(next_btn):\n",
    "    next_btn = next_btn\n",
    "    next_btn.click()\n",
    "    \n",
    "#clear searchbox\n",
    "def clearBox(box):\n",
    "    search_box = box\n",
    "    search_box.clear();\n",
    "\n",
    "#gather all titles appearing in the page searched\n",
    "def one_page_all_title(page):\n",
    "    title_box = []\n",
    "    for single in page.find_all('p', {'class' : 'title'}):\n",
    "        title = single.find('a').text\n",
    "        title_box.append(title)\n",
    "    return title_box\n",
    "\n",
    "#gather all urls linked to each individual search results\n",
    "def one_page_all_url(page):\n",
    "    link_box = []\n",
    "    for single in page.find_all('p', {'class' : 'title'}):\n",
    "        url = single.find_all('a')[0]\n",
    "        url = url['href']\n",
    "        link_box.append(url)\n",
    "    return link_box\n",
    "\n",
    "def page_num(page):\n",
    "    single = page.find('h3', {'class' : 'page'})\n",
    "    single = single.find('input', {'class' : 'num'})\n",
    "    print(single)\n",
    "    return int(single['value']), int(single['last'])\n",
    "    \n",
    "\n",
    "def get_response(url):\n",
    "        response = requests.get(url).txt\n",
    "        return reponse\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd35e7",
   "metadata": {},
   "source": [
    "# Execute by order ↓\n",
    "\n",
    "# Second-level functions\n",
    "\n",
    "The code below contains second-level functions that are used to find URLs for each of the titles retrieved from a page. These functions include:\n",
    "\n",
    "- `one_page_summary(page, dp, test, i)`: This function takes a page, a DataFrame `dp`, a list `test`, and an index `i`. It retrieves the titles and URLs from the page, prepends the URLs with a front URL, and creates a new DataFrame `dp2` with the gene, title, and URL information. The function then concatenates `dp` and `dp2` and returns the resulting DataFrame.\n",
    "- `prepend(ls, form)`: This function takes a list `ls` and a string `form`. It prepends each element in the list with the specified format `form` and returns the modified list.\n",
    "\n",
    "These functions are used to gather information from the retrieved page, format the URLs, and create a new DataFrame with the gene, title, and URL information. The resulting DataFrame is then concatenated with the original DataFrame.\n",
    "\n",
    "Please note that this Markdown cell provides a brief overview of the functions included in the code. For more details on each function's implementation and usage, please refer to the code itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a455caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second-level functions\n",
    "#find urls for each of the titles\n",
    "def one_page_summary(page, dp, test, i):\n",
    "    title_list = one_page_all_title(page)\n",
    "    url_list = one_page_all_url(page)\n",
    "    front_url = 'https://ncbi.nlm.nih.gov'\n",
    "    \n",
    "    url_list = prepend(url_list, front_url)\n",
    "    \n",
    "    current_gene = [test[i]] * len(url_list) #test is used here again\n",
    "    all_list = [current_gene, title_list, url_list]\n",
    "\n",
    "    dp2 = pd.DataFrame({\n",
    "        'Gene': current_gene,\n",
    "        'Title': title_list,\n",
    "        'Link':  url_list\n",
    "    })\n",
    "\n",
    "    return pd.concat([dp, dp2], ignore_index=True)\n",
    "\n",
    "def prepend(ls, form):\n",
    " \n",
    "    # Using format()\n",
    "    form += '{0}'\n",
    "    ls = [form.format(i) for i in ls]\n",
    "    return ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9349e",
   "metadata": {},
   "source": [
    "# 'TF3.xlsx' must be present in the directory in which this code is located. Otherwise, need to be modified to fit the needs. \n",
    "# In the excel file which gene list will be imported, gene = df.iloc[:,0].tolist() means gene list needs to be at the first column\n",
    "\n",
    "# Data Retrieval from GEO Website\n",
    "\n",
    "The code below demonstrates the process of retrieving data from the GEO website using Selenium and BeautifulSoup. Here's an overview of the code:\n",
    "\n",
    "1. Reading the input data: The code reads an Excel file ('TF3.xlsx') into a DataFrame called `df`. It then extracts the gene names from the first column of the DataFrame.\n",
    "\n",
    "2. Initializing variables: The code initializes variables including `test` (used for test searches), `dp` (an empty DataFrame to store the results), and `driver` (the web driver for Selenium).\n",
    "\n",
    "3. Opening the GEO website: The code opens the GEO website using the `open_geo()` function. It sets the search box and search button variables using the `set_box()` and `set_btn()` functions.\n",
    "\n",
    "4. Performing searches: The code loops through each gene in the `test` list. For each gene, it types the gene name into the search box and clicks the search button using the `type_click()` function.\n",
    "\n",
    "5. Handling search results: The code checks if there are any search results. If there are no results, it adds a row with NaN values to the DataFrame `dp`. If there are results, it retrieves the titles and URLs from the current page using the `one_page_all_title()` and `one_page_all_url()` functions. It then calls the `one_page_summary()` function to add the gene, title, and URL information to the DataFrame `dp`.\n",
    "\n",
    "6. Handling multiple pages: If there are multiple pages of search results, the code navigates through the pages using the next button. It clicks the next button, updates the search box and search button variables, retrieves the new page source, and repeats the process of retrieving titles and URLs from the page using the `one_page_all_title()` and `one_page_all_url()` functions.\n",
    "\n",
    "7. Saving the results: The code saves the resulting DataFrame `dp` to an Excel file named 'test.xlsx' using the `to_excel()` function.\n",
    "\n",
    "8. Generating distinct values: The code generates a list `distinct_values` that contains the number of distinct values for each column in the DataFrame `dp`.\n",
    "\n",
    "Please note that this Markdown cell provides a brief overview of the code. For more details on each function's implementation and usage, please refer to the code itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5100aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HES4', 'NKX2-1', 'SOX3', 'POU3F1', 'HES1']\n"
     ]
    }
   ],
   "source": [
    "#open list of genes and save it as list\n",
    "df = pd.read_excel('TF3.xlsx')\n",
    "gene = df.iloc[:,0].tolist()\n",
    "print(gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3431b67",
   "metadata": {},
   "source": [
    "# After below code is executed, a pop-up window will appear and program will start to run. To abort, press ■ in the menubar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa097dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choyo\\AppData\\Local\\Temp\\ipykernel_12472\\2777344704.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#test for searches\n",
    "test = gene \n",
    "dp = pd.DataFrame(columns = ['Gene', 'Title', 'Link'])\n",
    "\n",
    "#open geo website\n",
    "driver = open_geo()\n",
    "box = set_box(driver)\n",
    "btn = set_btn(driver)\n",
    "\n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    type_click(test[i], box, btn) #change [test] to [gene] for search over entire genes\n",
    "    #repeat below 5 everytime page changes/refreshes\n",
    "    box = set_box(driver)\n",
    "    btn = set_btn(driver)\n",
    "    next_btn = set_next1(driver) #either the button exists or next_btn is 0\n",
    "    src = driver.page_source\n",
    "    page = bs4.BeautifulSoup(src)\n",
    "    \n",
    "    \n",
    "    #find the number of titles current page. number of titles = number of search results \n",
    "    title_list = one_page_all_title(page)\n",
    "    #find number of total pages,\n",
    "    n_of_titles = len(title_list)   \n",
    "    clearBox(box)     \n",
    "    \n",
    "    #if no search results, go next\n",
    "    if(n_of_titles == 0):\n",
    "        \n",
    "        dp2 = pd.DataFrame({\n",
    "            'Gene': [test[i]],\n",
    "            'Title': [np.nan],\n",
    "            'Link':  [np.nan]\n",
    "        })\n",
    "        dp = pd.concat([dp, dp2], ignore_index=True)\n",
    "        \n",
    "        \n",
    "    else:     \n",
    "        #if # of search results <= 20\n",
    "        if(next_btn == 0):\n",
    "            dp = one_page_summary(page, dp, test, i)\n",
    "        else:\n",
    "            current, last = page_num(page)\n",
    "            while current <= last:\n",
    "                if current == last:\n",
    "                        dp = one_page_summary(page, dp, test, i)\n",
    "                else:\n",
    "                        dp = one_page_summary(page, dp, test, i)\n",
    "                        click_next(next_btn)\n",
    "                        box = set_box(driver)\n",
    "                        btn = set_btn(driver)\n",
    "                        next_btn = set_next2(driver) #either the button exists or next_btn is 0\n",
    "                        src = driver.page_source\n",
    "                        page = bs4.BeautifulSoup(src)\n",
    "                current += 1\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "dp.to_excel('test.xlsx', index = False, encoding = 'utf8')\n",
    "gene_output = dp.iloc[:,0].tolist()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a86beb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_values = []\n",
    "for col in dp.columns:\n",
    "    #dinstincts\n",
    "    distinct_values.append(len(dp[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e0cfc24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 40, 40]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a82df",
   "metadata": {},
   "source": [
    "## Part2\n",
    "\n",
    "### Data Processing from Retrieved Results\n",
    "\n",
    "The code below demonstrates the process of processing the retrieved results from the previously saved Excel file ('test.xlsx'). Here's an overview of the code:\n",
    "\n",
    "1. Reading the retrieved results: The code reads the Excel file ('test.xlsx') into a DataFrame called `df`. It extracts the URLs and gene names from the DataFrame.\n",
    "\n",
    "2. Processing the URLs: The code retrieves the URLs from the DataFrame using the `iloc` function and stores them in a list called `urls`. It also retrieves the first URL from the list and assigns it to a variable `urls[0]`.\n",
    "\n",
    "3. Processing the gene names: The code retrieves the gene names from the DataFrame using the `iloc` function and stores them in a list called `genes`.\n",
    "\n",
    "Please note that this Markdown cell provides a brief overview of the code. For more details on each step's implementation and usage, please refer to the code itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d88f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open list of genes and save it as list\n",
    "df = pd.read_excel('test.xlsx')\n",
    "urls = df.iloc[:,2].tolist()\n",
    "urls[0]\n",
    "genes = df.iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20173a34",
   "metadata": {},
   "source": [
    "# Data Processing from Retrieved Results (Part 2)\n",
    "\n",
    "The code below continues the data processing from the retrieved results. It includes several functions for further processing and analysis. Here's an overview of the functions:\n",
    "\n",
    "1. `open_url(url, dr)`: This function opens a given URL using the provided driver (`dr`). It checks if the URL is not null before opening it.\n",
    "\n",
    "2. `find_journal(page)`: This function searches for the journal information on the given page and returns the journal name. If the journal information is not found, it returns NaN.\n",
    "\n",
    "3. `find_organization(page)`: This function searches for the organization name on the given page and returns the organization name. If the organization information is not found, it returns NaN.\n",
    "\n",
    "4. `second_largest(ls)`: This function finds the second-largest value in a list (`ls`) and returns it.\n",
    "\n",
    "5. `set_more(dr)`: This function finds and sets the \"More\" button on the page. It checks for the existence of the button at different positions and returns the appropriate button element.\n",
    "\n",
    "6. `qc_status(page)`: This function calculates the quality control status based on the presence of \"PassedQC\" and \"FailedQC\" strings on the page. It returns the percentage of passed QC and failed QC.\n",
    "\n",
    "7. `gdv_checker(page, dr)`: This function checks for the existence of the \"gdv_button\" on the page using the provided driver (`dr`). It returns a status indicating its existence.\n",
    "\n",
    "8. `count_gene(page, gene, i)`: This function counts the occurrences of a specific gene (`gene[i]`) on the page. It returns a string with all the gene names and the total count.\n",
    "\n",
    "Please note that this Markdown cell provides a brief overview of the code. For more details on each function's implementation and usage, please refer to the code itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2512e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_url(url, dr):\n",
    "    if(pd.isnull(url) == False):\n",
    "        dr.get(url)\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "#gather all titles appearing in the page searched\n",
    "def find_journal(page):\n",
    "    try:\n",
    "        jrl = page.find(\"span\", \"source\")\n",
    "        return jrl.text\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def find_organization(page):\n",
    "    try:\n",
    "        org = page.find(\"td\", text=\"Organization name\").find_next_sibling(\"td\")\n",
    "        return org.text\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def second_largest(ls):\n",
    "    ls.sort()\n",
    "    return ls[-2]\n",
    "\n",
    "#find and set more button\n",
    "def set_more(dr):\n",
    "    all_more = []\n",
    "    two_mores = 0\n",
    "    \n",
    "    for i in range(20,30):\n",
    "        more_btn_path = '/html/body/table/tbody/tr/td/table[6]/tbody/tr[3]/td[2]/table/tbody/tr/td/table/tbody/tr/td/table[2]/tbody/tr/td/table[1]/tbody/tr['+ str(i)+']/td[1]/div[2]/a'\n",
    "        #check if more button exists\n",
    "        status = check_exists_by_xpath(more_btn_path, dr)\n",
    "        if(status == 0):\n",
    "            all_more.append(0)\n",
    "        else:\n",
    "            all_more.append(i)    \n",
    "    if(max(all_more) == 0):\n",
    "        return 0       \n",
    "    else:\n",
    "        if(all_more.count(0) == 7):\n",
    "            target = second_largest(all_more)\n",
    "            more_btn_path = '/html/body/table/tbody/tr/td/table[6]/tbody/tr[3]/td[2]/table/tbody/tr/td/table/tbody/tr/td/table[2]/tbody/tr/td/table[1]/tbody/tr['+ str(target)+']/td[1]/div[2]/a'\n",
    "            #more_btn = driver.find_element_by_xpath(more_btn_path)\n",
    "            more_btn = driver.find_element(By.XPATH, more_btn_path)\n",
    "            return more_btn\n",
    "        else:\n",
    "            more_btn_path = '/html/body/table/tbody/tr/td/table[6]/tbody/tr[3]/td[2]/table/tbody/tr/td/table/tbody/tr/td/table[2]/tbody/tr/td/table[1]/tbody/tr['+ str(max(all_more))+']/td[1]/div[2]/a'\n",
    "            #more_btn = driver.find_element_by_xpath(more_btn_path)\n",
    "            more_btn = driver.find_element(By.XPATH, more_btn_path)\n",
    "            return more_btn\n",
    "        \n",
    "\n",
    "def qc_status(page):\n",
    "    passQC = page.find_all(string=re.compile(\"PassedQC\"))\n",
    "    failQC = page.find_all(string=re.compile(\"FailedQC\"))\n",
    "    pQC = len(passQC)\n",
    "    fQC = len(failQC)\n",
    "    if (pQC == 0 and fQC == 0):\n",
    "        return 0, 0\n",
    "    else:\n",
    "        return round(pQC/(pQC+fQC), 2), round(fQC/(pQC+fQC), 2)\n",
    "\n",
    "def gdv_checker(page, dr):\n",
    "    gdv_btn_path = '//*[@id=\"gdv_button\"]/span'\n",
    "    status = check_exists_by_xpath(gdv_btn_path, dr)\n",
    "    return status\n",
    "\n",
    "def count_gene(page, gene, i):\n",
    "    all_names = \"\"\n",
    "    total = page.find_all(string=re.compile(str(gene[i])))\n",
    "    for single in page.find_all(string=re.compile(str(gene[i]))):\n",
    "        all_names = all_names + \"|\" + str(single)\n",
    "    \n",
    "    return all_names, len(total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1c87c",
   "metadata": {},
   "source": [
    "# Data Processing from Retrieved Results (Part 3)\n",
    "\n",
    "The code below continues the data processing from the retrieved results. It retrieves additional information from the pages obtained earlier. Here's an overview of the code:\n",
    "\n",
    "1. **Read the Excel File:** `workbook_df = pd.read_excel('test.xlsx')`\n",
    "   - This line reads the previously saved Excel file (`test.xlsx`) into a DataFrame called `workbook_df`.\n",
    "\n",
    "2. **Define Variables:**\n",
    "   - `test = urls`\n",
    "     - This line assigns the list of URLs (`urls`) to the variable `test`.\n",
    "\n",
    "3. **Initialize Lists for Retrieved Information:**\n",
    "   - `journal = []`, `organization = []`, `fQC = []`, `pQC = []`, `GDV = []`, `appearance = []`, `ref_num = []`\n",
    "     - These lines initialize empty lists to store the retrieved information.\n",
    "\n",
    "4. **Iterate Over URLs:**\n",
    "   - The code then iterates over each URL in `test` using a for loop.\n",
    "\n",
    "5. **Retrieve Information from Page:**\n",
    "   - Inside the loop, it checks if the URL is not null using the `open_url(url, dr)` function. If the URL is not null, it proceeds with retrieving information from the page.\n",
    "\n",
    "6. **Parse HTML and Retrieve Page Information:**\n",
    "   - It retrieves the page source and creates a BeautifulSoup object (`page`) to parse the HTML.\n",
    "\n",
    "7. **Check for \"More\" Button and Update Page:**\n",
    "   - It checks for the existence of the \"More\" button using the `set_more(dr)` function. If the button exists, it clicks the button and retrieves the updated page source, creating a new BeautifulSoup object (`page`).\n",
    "\n",
    "8. **Retrieve Journal Information:**\n",
    "   - It retrieves the journal information using the `find_journal(page)` function and stores it in the `journal` list.\n",
    "\n",
    "9. **Retrieve Organization Information:**\n",
    "   - It retrieves the organization information using the `find_organization(page)` function and stores it in the `organization` list.\n",
    "\n",
    "10. **Calculate QC Status:**\n",
    "    - It calculates the QC status using the `qc_status(page)` function and stores the percentage of passed QC and failed QC in the `pQC` and `fQC` lists, respectively.\n",
    "\n",
    "11. **Check for \"gdv_button\" and Store Result:**\n",
    "    - It checks for the existence of the \"gdv_button\" using the `gdv_checker(page, dr)` function and stores the result in the `GDV` list.\n",
    "\n",
    "12. **Count Gene Appearances on the Page:**\n",
    "    - It counts the appearance of genes on the page using the `count_gene(page, genes, i)` function and stores the results in the `appearance` and `ref_num` lists.\n",
    "\n",
    "13. **Handle Null URLs:**\n",
    "    - If the URL is null, it appends NaN values to all the lists.\n",
    "\n",
    "14. **Add Retrieved Information to DataFrame:**\n",
    "    - After processing all URLs, it adds the retrieved information to the `workbook_df` DataFrame.\n",
    "\n",
    "15. **Save Updated DataFrame to Excel File:**\n",
    "    - Finally, it saves the updated DataFrame to a new Excel file called `test_final.xlsx`.\n",
    "\n",
    "Please note that this Markdown cell provides a brief overview of the code. For more details on each function's implementation and usage, please refer to the code itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7077e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook_df =pd.read_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdacae4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choyo\\AppData\\Local\\Temp\\ipykernel_12472\\2295877218.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#test for searches\n",
    "test = urls\n",
    "#test = urls\n",
    "driver = Chrome(\"chromedriver.exe\")\n",
    "journal = []\n",
    "organization = []\n",
    "fQC = []\n",
    "pQC = []\n",
    "GDV = []\n",
    "appearance = []\n",
    "ref_num = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    is_null = open_url(test[i], driver)\n",
    "    \n",
    "    if(is_null == 1):\n",
    "        time.sleep(0.5)\n",
    "        src = driver.page_source\n",
    "        page = bs4.BeautifulSoup(src)\n",
    "        \n",
    "        more_btn = set_more(driver)\n",
    "        if (more_btn != 0):\n",
    "            more_btn.click()\n",
    "            time.sleep(0.5)\n",
    "            page = bs4.BeautifulSoup(src)\n",
    "        \n",
    "        jrl = find_journal(page) #pass\n",
    "        org = find_organization(page) #pass  \n",
    "        pass_QC, fail_QC = qc_status(page) #pass\n",
    "        gdv_btn = gdv_checker(page, driver) #pass\n",
    "        appear, refnum = count_gene(page, genes, i) #pass\n",
    "        \n",
    "        journal.append(jrl)\n",
    "        organization.append(org)\n",
    "        fQC.append(str(fail_QC))\n",
    "        pQC.append(str(pass_QC))\n",
    "        GDV.append(gdv_btn)\n",
    "        appearance.append(appear)\n",
    "        ref_num.append(refnum)\n",
    "    \n",
    "    else:\n",
    "        journal.append(np.nan)\n",
    "        organization.append(np.nan)\n",
    "        fQC.append(np.nan)\n",
    "        pQC.append(np.nan)\n",
    "        GDV.append(np.nan)\n",
    "        appearance.append(np.nan)\n",
    "        ref_num.append(np.nan)\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eab0f9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(len(journal))\n",
    "print(len(organization))\n",
    "print(len(fQC))\n",
    "print(len(pQC))\n",
    "print(len(GDV))\n",
    "print(len(appearance))\n",
    "print(len(ref_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aac33f",
   "metadata": {},
   "source": [
    "# Convert to dataframe for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1a5af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook_df['Journal'] = journal\n",
    "workbook_df['organization'] =organization\n",
    "workbook_df['fQC'] =fQC\n",
    "workbook_df['pQC'] =pQC\n",
    "workbook_df['GDV'] =GDV\n",
    "workbook_df['appearance'] =appearance\n",
    "workbook_df['ref_num'] =ref_num\n",
    "workbook_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4bba9ea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save\n",
    "workbook_df.to_excel('test_final.xlsx', index = False, encoding = 'utf8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
